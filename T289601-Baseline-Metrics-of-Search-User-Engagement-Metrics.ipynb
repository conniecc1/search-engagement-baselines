{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38acabce",
   "metadata": {},
   "source": [
    "# Baseline Metrics of Search User Engagement Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1a023",
   "metadata": {},
   "source": [
    "[T289601](https://phabricator.wikimedia.org/T289601)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2a764",
   "metadata": {},
   "source": [
    "In this notebook, we establish baselines for search user engagement metrics for the Search Platform team.\n",
    "\n",
    "The metrics are (which we are tracking in dashbaord):\n",
    "- Number of search sessions (including full-text sessions, click sessions and checkin sessions).\n",
    "- Number of sessions with dwell time >= 10s.\n",
    "- Proportion of sessions with dwell time >= 10s.\n",
    "\n",
    "The projects we are tracking include:\n",
    "- Overall.\n",
    "- Major projects (from top 10 wikis): commons, wikidata, enwiki, eswiki, dewiki, jawiki, ruwiki, itwiki, zhwiki, ptwiki.\n",
    "- Projects of languages used in emerging market countries (Refer to [this sheet](https://docs.google.com/spreadsheets/d/14QzqCQeJbdfbXZOHDTYT5Ojd8pdisMpps37J7tvbNYo/edit?usp=sharing) for a detailed list of countries and languages).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e811ed4",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519e513",
   "metadata": {},
   "source": [
    "- Event logging in SearchSatisfaction is only done on the desktop platform. This means that for these metrics, platform will always be desktop. \n",
    "\n",
    "- For the baseline, we only look at user activities, which means the searches done by a bot or someone - who's likely a bot will not be included. If more than 50 searches are done in a session, it's likely a non-human agent and we'll label that automated. Otherwise, we'll label it user.\n",
    "\n",
    "- The timeframe is from 09/01/2021 to 09/30/2021 as the activities picked in from summer/vacation time.\n",
    "\n",
    "- We use median for daily metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e17ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from wmfdata import spark, mariadb, hive\n",
    "\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1be3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major projects that not in emerging coutries' language list\n",
    "major_project_list = '\"commonswiki\",\"wikidatawiki\",\"dewiki\",\"itwiki\",\"ruwiki\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f4e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "emerging_list = spark.run('''\n",
    "SELECT project FROM cchen_search.emerging_market_list GROUP BY project\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2434a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging_project_list = str(emerging_list.project.tolist())[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc074fc",
   "metadata": {},
   "source": [
    "## Number of search sessions per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d4004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_session_query = '''\n",
    "\n",
    "SELECT \n",
    "  project_family,\n",
    "  wiki_db,\n",
    "  f.language_code,\n",
    "  PERCENTILE(f.num_fulltext_sessions,0.5) AS fulltext_sessions,\n",
    "  PERCENTILE(f.num_click_sessions, 0.5) AS click_sessions,\n",
    "  PERCENTILE(f.num_checkin_sessions,0.5) AS checkin_sessions\n",
    "FROM search_dashboard_data.fulltext_funnel_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND (f.wiki_db IN ({major}) OR f.wiki_db IN ({emerging}))\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY f.project_family, f.wiki_db,f.language_code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e6a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_session_all_query = '''\n",
    "WITH daily AS (\n",
    "   SELECT \n",
    "     log_date, \n",
    "     SUM(num_fulltext_sessions) AS num_fulltext_sessions,\n",
    "     SUM(num_click_sessions) AS num_click_sessions,\n",
    "     SUM(num_checkin_sessions) AS num_checkin_sessions\n",
    "   FROM search_dashboard_data.fulltext_funnel_counts\n",
    "   WHERE log_date >= \"2021-09-01\"\n",
    "     AND log_date < \"2021-10-01\"\n",
    "     AND agent_type = 'user'\n",
    "   GROUP BY log_date\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  'Overall' AS project_family,\n",
    "  'Overall' AS wiki_db,\n",
    "  'Overall' AS language_code,\n",
    "  PERCENTILE(num_fulltext_sessions, 0.5) AS fulltext_sessions,\n",
    "  PERCENTILE(num_click_sessions, 0.5) AS click_sessions,\n",
    "  PERCENTILE(num_checkin_sessions, 0.5) AS checkin_sessions\n",
    "FROM daily\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d7c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "search_session_daily = spark.run(search_session_query.format(major = major_project_list, emerging = emerging_project_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "712402f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "search_session_overall_daily = spark.run(search_session_all_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dab3aa",
   "metadata": {},
   "source": [
    "## Sessions with dwell time >= 10s per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22a5aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_session_query = '''\n",
    "\n",
    "WITH daily AS (\n",
    "  SELECT \n",
    "    log_date,\n",
    "    project_family,\n",
    "    wiki_db,\n",
    "    f.language_code,\n",
    "    SUM(IF(max_checkin >= 10, num_sessions, 0)) AS num_dwell,\n",
    "    ROUND(100 * SUM(IF(max_checkin >= 10, num_sessions, 0)) /\n",
    "        SUM(num_sessions),2) AS percent_dwell\n",
    "FROM search_dashboard_data.fulltext_checkin_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND (f.wiki_db IN ({major}) OR f.wiki_db IN ({emerging}))\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY log_date, f.project_family, f.wiki_db,f.language_code\n",
    "\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  project_family,\n",
    "  wiki_db,\n",
    "  language_code,\n",
    "  PERCENTILE(num_dwell, 0.5) AS num_dwell,\n",
    "  PERCENTILE(percent_dwell, 0.5) AS percent_dwell\n",
    "FROM daily\n",
    "GROUP BY project_family, wiki_db,language_code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4f2db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_session_all_query = '''\n",
    "\n",
    "WITH daily AS (\n",
    "  SELECT \n",
    "    log_date,\n",
    "    SUM(IF(max_checkin >= 10, num_sessions, 0)) AS num_dwell,\n",
    "    ROUND(100 * SUM(IF(max_checkin >= 10, num_sessions, 0)) /\n",
    "        SUM(num_sessions),2) AS percent_dwell\n",
    "FROM search_dashboard_data.fulltext_checkin_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY log_date\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  'Overall' AS project_family,\n",
    "  'Overall' AS wiki_db,\n",
    "  'Overall' AS language_code,\n",
    "  PERCENTILE(num_dwell, 0.5) AS num_dwell,\n",
    "  PERCENTILE(percent_dwell, 0.5) AS percent_dwell\n",
    "FROM daily\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c973ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "dwell_session_daily = spark.run(dwell_session_query.format(major = major_project_list, emerging = emerging_project_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e183f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "dwell_session_overall_daily = spark.run(dwell_session_all_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa25eb",
   "metadata": {},
   "source": [
    "## export to google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eca45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = Credentials.from_service_account_file('big-mender-274521-324384a764e2.json', scopes=scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a01f3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def sheet1(self):\n",
    "    \"\"\"Shortcut property for getting the first worksheet.\"\"\"\n",
    "    return self.get_worksheet(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "320c9eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'updatedRange': 'Sheet4!A1:F38',\n",
       " 'updatedRows': 38,\n",
       " 'updatedColumns': 6,\n",
       " 'updatedCells': 228}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks1 = gc.open(\"search_engagement_baselines\").get_worksheet(0)\n",
    "wks1.update([search_session_daily.columns.values.tolist()] + search_session_daily.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2aa580a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'tableRange': 'Sheet4!A1:F38',\n",
       " 'updates': {'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       "  'updatedRange': 'Sheet4!A39:F39',\n",
       "  'updatedRows': 1,\n",
       "  'updatedColumns': 6,\n",
       "  'updatedCells': 6}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks1.append_row(search_session_overall_daily.iloc[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f75678b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'updatedRange': 'Sheet3!A1:E38',\n",
       " 'updatedRows': 38,\n",
       " 'updatedColumns': 5,\n",
       " 'updatedCells': 190}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks2 = gc.open(\"search_engagement_baselines\").get_worksheet(1)\n",
    "wks2.update([dwell_session_daily.columns.values.tolist()] + dwell_session_daily.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f61df1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'tableRange': 'Sheet3!A1:E38',\n",
       " 'updates': {'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       "  'updatedRange': 'Sheet3!A39:E39',\n",
       "  'updatedRows': 1,\n",
       "  'updatedColumns': 5,\n",
       "  'updatedCells': 5}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks2.append_row(dwell_session_overall_daily.iloc[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361e923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
