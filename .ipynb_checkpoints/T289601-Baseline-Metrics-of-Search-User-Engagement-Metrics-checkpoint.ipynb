{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d848e197",
   "metadata": {},
   "source": [
    "# Baseline Metrics of Search User Engagement Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdff5fe",
   "metadata": {},
   "source": [
    "[T289601](https://phabricator.wikimedia.org/T289601)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da3ba3",
   "metadata": {},
   "source": [
    "In this notebook, we establish baselines for search user engagement metrics for the Search Platform team.\n",
    "\n",
    "The metrics are (which we are tracking in dashbaord):\n",
    "- Number of search sessions (including full-text sessions, click sessions and checkin sessions).\n",
    "- Number of sessions with dwell time >= 10s.\n",
    "- Proportion of sessions with dwell time >= 10s.\n",
    "\n",
    "The projects we are tracking include:\n",
    "- Overall.\n",
    "- Major projects (from top 10 wikis): commons, wikidata, enwiki, eswiki, dewiki, jawiki, ruwiki, itwiki, zhwiki, ptwiki.\n",
    "- Projects of languages used in emerging market countries (Refer to [this sheet](https://docs.google.com/spreadsheets/d/14QzqCQeJbdfbXZOHDTYT5Ojd8pdisMpps37J7tvbNYo/edit?usp=sharing) for a detailed list of countries and languages).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcb954",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24aaa0e",
   "metadata": {},
   "source": [
    "Event logging in SearchSatisfaction is only done on the desktop platform. This means that for these metrics, platform will always be desktop. \n",
    "\n",
    "For the baseline, we only look at user activities, which means the searches done by a bot or someone who's likely a bot will not be included. If more than 50 searches are done in a session, it's likely a non-human agent and we'll label that automated. Otherwise, we'll label it user.\n",
    "\n",
    "The timeframe is from 09/01/2021 to 09/30/2021 as the activities picked in from summer/vacation time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8451b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from wmfdata import spark, mariadb, hive\n",
    "\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8478923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major projects that not in emerging coutries' language list\n",
    "major_project_list = '\"commonswiki\",\"wikidatawiki\",\"dewiki\",\"itwiki\",\"ruwiki\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fe1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "emerging_list = spark.run('''\n",
    "SELECT project FROM cchen_search.emerging_market_list GROUP BY project\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bad5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging_project_list = str(emerging_list.project.tolist())[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d388b",
   "metadata": {},
   "source": [
    "## Number of search sessions per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4baf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_session_query = '''\n",
    "\n",
    "SELECT \n",
    "  project_family,\n",
    "  wiki_db,\n",
    "  f.language_code,\n",
    "  PERCENTILE(f.num_fulltext_sessions,0.5) AS fulltext_sessions,\n",
    "  PERCENTILE(f.num_click_sessions, 0.5) AS click_sessions,\n",
    "  PERCENTILE(f.num_checkin_sessions,0.5) AS checkin_sessions\n",
    "FROM search_dashboard_data.fulltext_funnel_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND (f.wiki_db IN ({major}) OR f.wiki_db IN ({emerging}))\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY f.project_family, f.wiki_db,f.language_code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefcdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_session_all_query = '''\n",
    "WITH daily AS (\n",
    "   SELECT \n",
    "     log_date, \n",
    "     SUM(num_fulltext_sessions) AS num_fulltext_sessions,\n",
    "     SUM(num_click_sessions) AS num_click_sessions,\n",
    "     SUM(num_checkin_sessions) AS num_checkin_sessions\n",
    "   FROM search_dashboard_data.fulltext_funnel_counts\n",
    "   WHERE log_date >= \"2021-09-01\"\n",
    "     AND log_date < \"2021-10-01\"\n",
    "     AND agent_type = 'user'\n",
    "   GROUP BY log_date\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  'Overall' AS project_family,\n",
    "  'Overall' AS wiki_db,\n",
    "  'Overall' AS language_code,\n",
    "  PERCENTILE(num_fulltext_sessions, 0.5) AS fulltext_sessions,\n",
    "  PERCENTILE(num_click_sessions, 0.5) AS click_sessions,\n",
    "  PERCENTILE(num_checkin_sessions, 0.5) AS checkin_sessions\n",
    "FROM daily\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "243d47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "search_session_daily = spark.run(search_session_query.format(major = major_project_list, emerging = emerging_project_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60f420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "search_session_overall_daily = spark.run(search_session_all_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec825c84",
   "metadata": {},
   "source": [
    "## Sessions with dwell time >= 10s per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "217c1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_session_query = '''\n",
    "\n",
    "WITH daily AS (\n",
    "  SELECT \n",
    "    log_date,\n",
    "    project_family,\n",
    "    wiki_db,\n",
    "    f.language_code,\n",
    "    SUM(IF(max_checkin >= 10, num_sessions, 0)) AS num_dwell,\n",
    "    ROUND(100 * SUM(IF(max_checkin >= 10, num_sessions, 0)) /\n",
    "        SUM(num_sessions),2) AS percent_dwell\n",
    "FROM search_dashboard_data.fulltext_checkin_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND (f.wiki_db IN ({major}) OR f.wiki_db IN ({emerging}))\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY log_date, f.project_family, f.wiki_db,f.language_code\n",
    "\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  project_family,\n",
    "  wiki_db,\n",
    "  language_code,\n",
    "  PERCENTILE(num_dwell, 0.5) AS num_dwell,\n",
    "  PERCENTILE(percent_dwell, 0.5) AS percent_dwell\n",
    "FROM daily\n",
    "GROUP BY project_family, wiki_db,language_code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "234e2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_session_all_query = '''\n",
    "\n",
    "WITH daily AS (\n",
    "  SELECT \n",
    "    log_date,\n",
    "    SUM(IF(max_checkin >= 10, num_sessions, 0)) AS num_dwell,\n",
    "    ROUND(100 * SUM(IF(max_checkin >= 10, num_sessions, 0)) /\n",
    "        SUM(num_sessions),2) AS percent_dwell\n",
    "FROM search_dashboard_data.fulltext_checkin_counts f\n",
    "WHERE log_date >= \"2021-09-01\"\n",
    "  AND log_date < \"2021-10-01\"\n",
    "  AND agent_type = 'user'\n",
    "GROUP BY log_date\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  'Overall' AS project_family,\n",
    "  'Overall' AS wiki_db,\n",
    "  'Overall' AS language_code,\n",
    "  PERCENTILE(num_dwell, 0.5) AS num_dwell,\n",
    "  PERCENTILE(percent_dwell, 0.5) AS percent_dwell\n",
    "FROM daily\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8870cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "dwell_session_daily = spark.run(dwell_session_query.format(major = major_project_list, emerging = emerging_project_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d1d6938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "dwell_session_overall_daily = spark.run(dwell_session_all_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684dedc",
   "metadata": {},
   "source": [
    "## export to google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7ca545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = Credentials.from_service_account_file('big-mender-274521-324384a764e2.json', scopes=scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b12b144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def sheet1(self):\n",
    "    \"\"\"Shortcut property for getting the first worksheet.\"\"\"\n",
    "    return self.get_worksheet(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65b0748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'updatedRange': 'Sheet4!A1:F38',\n",
       " 'updatedRows': 38,\n",
       " 'updatedColumns': 6,\n",
       " 'updatedCells': 228}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks1 = gc.open(\"search_engagement_baselines\").get_worksheet(0)\n",
    "wks1.update([search_session_daily.columns.values.tolist()] + search_session_daily.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8578de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'tableRange': 'Sheet4!A1:F38',\n",
       " 'updates': {'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       "  'updatedRange': 'Sheet4!A39:F39',\n",
       "  'updatedRows': 1,\n",
       "  'updatedColumns': 6,\n",
       "  'updatedCells': 6}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks1.append_row(search_session_overall_daily.iloc[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71591ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'updatedRange': 'Sheet3!A1:E38',\n",
       " 'updatedRows': 38,\n",
       " 'updatedColumns': 5,\n",
       " 'updatedCells': 190}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks2 = gc.open(\"search_engagement_baselines\").get_worksheet(1)\n",
    "wks2.update([dwell_session_daily.columns.values.tolist()] + dwell_session_daily.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5651678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       " 'tableRange': 'Sheet3!A1:E38',\n",
       " 'updates': {'spreadsheetId': '1FOI2nLcuaj4CPY-G0Uz460oM_2UIPTViYRAFWAXrQ6M',\n",
       "  'updatedRange': 'Sheet3!A39:E39',\n",
       "  'updatedRows': 1,\n",
       "  'updatedColumns': 5,\n",
       "  'updatedCells': 5}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wks2.append_row(dwell_session_overall_daily.iloc[-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22fd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
